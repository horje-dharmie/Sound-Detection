{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "664e7794-fffc-4b92-9727-bcc5631cece1",
   "metadata": {
    "id": "664e7794-fffc-4b92-9727-bcc5631cece1"
   },
   "source": [
    "## IMPORTING LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db937e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sc\n",
    "import IPython.display as ipd\n",
    "from scipy import signal\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io.wavfile as wavfile\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import sklearn\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import *\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f0a199",
   "metadata": {},
   "source": [
    "## LOADING IN THE FILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8016486c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import os\n",
    "ROOT_DIR = '/Users/damilolaojedeji/Documents/Classes/Fall 2022/ML/Assignment2/'\n",
    "#Files = [f'{ROOT_DIR}/Music/'+file for file in os.listdir(f'{ROOT_DIR}/Music')]\n",
    "Files =[]\n",
    "Folders=[\"Blender\",\"Microwave\",\"Music\",\"Siren\", \"Vacuum\"]\n",
    "for folder in Folders:\n",
    "    for file in os.listdir(f'{ROOT_DIR}/{folder}'):\n",
    "        if \"wav\" in file:\n",
    "            Files.append(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e70f50c",
   "metadata": {},
   "source": [
    "## PREDICTION WITHOUT BINNING AND WINDOWING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974cfc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "FFT_SIZE = 2048\n",
    "feature_df = pd.DataFrame(columns = ['label']+['max_freq', 'mean_freq', 'std_freq'])\n",
    "for folder in Folders:\n",
    "    files = librosa.util.find_files(f\"{ROOT_DIR}/{folder}\", ext=['wav']) \n",
    "    files = np.asarray(files)\n",
    "    for file_path in files:\n",
    "        audio = librosa.load(file_path, sr=None, mono=True, offset=0.0, duration=None)\n",
    "        audio_file = librosa.effects.trim(audio[0])  #trim audio\n",
    "        spectrogram = signal.spectrogram(audio_file[0], nperseg=FFT_SIZE, fs=audio[1], noverlap=FFT_SIZE/2)\n",
    "        log_spectogram = np.log((spectrogram[2])+.0001) #.0001 to prevent math error\n",
    "        \n",
    "        max_freq = np.max(log_spectogram) #max frequency\n",
    "       \n",
    "        mean_freq = np.mean(log_spectogram) #mean frequency\n",
    "        \n",
    "        std_freq = np.std(log_spectogram) #std frequency                   \n",
    "    \n",
    "    \n",
    "        feature_df.loc[len(feature_df)] = [folder, max_freq, mean_freq, std_freq]# append features to feature df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b90bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into features and labels\n",
    "feature_data = feature_df[['max_freq', 'mean_freq', 'std_freq']] #features\n",
    "feature_labels = feature_df['label']  #labels\n",
    "scaler = RobustScaler() #normalize data for better prediction\n",
    "feature_data = scaler.fit_transform(feature_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f350d4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(feature_data, feature_labels, test_size=0.30)\n",
    "\n",
    "#training the model\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(xtrain, ytrain)\n",
    "cv_scores = cross_val_score(clf, xtrain, ytrain, cv=10)\n",
    "print('Average Cross Validation Score from Training:', cv_scores.mean(), sep='\\n', end='\\n\\n\\n')\n",
    "\n",
    "#testing the model\n",
    "ypred = clf.predict(xtest)\n",
    "cm = confusion_matrix(ytest, ypred)\n",
    "cr = classification_report(ytest, ypred)\n",
    "\n",
    "print('Confusion Matrix:', cm, sep='\\n', end='\\n\\n\\n')\n",
    "print('Test Statistics:', cr, sep='\\n', end='\\n\\n\\n')\n",
    "\n",
    "print('Testing Accuracy:', accuracy_score(ytest, ypred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac009e0",
   "metadata": {},
   "source": [
    "## PREDICTION WITH BINNING BUT WITHOUT WINDOWING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b22f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "FFT_SIZE = 2048\n",
    "num_time_bins = 10\n",
    "num_freq_bins = 10\n",
    "Features = []\n",
    "feature_df_bin = pd.DataFrame(columns = ['label']+['max_freq', 'mean_freq', 'std_freq'])\n",
    "for folder in Folders:\n",
    "    files = librosa.util.find_files(f\"{ROOT_DIR}/{folder}\", ext=['wav']) \n",
    "    files = np.asarray(files)\n",
    "    for file_path in files:\n",
    "        audio = librosa.load(file_path, sr=None, mono=True, offset=0.0, duration=None)\n",
    "        audio_file = librosa.effects.trim(audio[0])\n",
    "        spectrogram = signal.spectrogram(audio_file[0], nperseg=FFT_SIZE, fs=audio[1], noverlap=FFT_SIZE/2)\n",
    "        \n",
    "        pxx = np.log((spectrogram[2])+.0001)\n",
    "        \n",
    "        resized_pxx = cv2.resize(pxx[:,:],(num_freq_bins,num_time_bins))#Binning\n",
    "        max_freq = np.max(resized_pxx) #max frequency\n",
    "      \n",
    "        mean_freq = np.mean(resized_pxx) # mean frequency\n",
    "        \n",
    "        std_freq = np.std(resized_pxx) #std frequency                  \n",
    "\n",
    "        feature_df_bin.loc[len(feature_df_bin)] = [folder, max_freq, mean_freq, std_freq] # append features to feature df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb5f372",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_data_bin = feature_df_bin[['max_freq', 'mean_freq', 'std_freq']]\n",
    "feature_labels = feature_df['label']\n",
    "scaler = RobustScaler()\n",
    "feature_data_bin = scaler.fit_transform(feature_data_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8e708f",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain, xtest, ytrain, ytest = train_test_split(feature_data_bin, feature_labels, test_size=0.30)\n",
    "\n",
    "#training the model\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(xtrain, ytrain)\n",
    "cv_scores = cross_val_score(clf, xtrain, ytrain, cv=10)\n",
    "print('Average Cross Validation Score from Training:', cv_scores.mean(), sep='\\n', end='\\n\\n\\n')\n",
    "\n",
    "#testing the model\n",
    "ypred = clf.predict(xtest)\n",
    "cm = confusion_matrix(ytest, ypred)\n",
    "cr = classification_report(ytest, ypred)\n",
    "\n",
    "print('Confusion Matrix:', cm, sep='\\n', end='\\n\\n\\n')\n",
    "print('Test Statistics:', cr, sep='\\n', end='\\n\\n\\n')\n",
    "print('Testing Accuracy:', accuracy_score(ytest, ypred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74400f81",
   "metadata": {},
   "source": [
    "## PREDICTION WITH BINNING AND WINDOWING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2985c2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_of_window = 5\n",
    "feature_wind = pd.DataFrame(columns = ['label']+['max_freq', 'mean_freq', 'std_freq']*no_of_window)\n",
    "\n",
    "\n",
    "\n",
    "# loop through .wav files\n",
    "for folder in Folders:\n",
    "    files = librosa.util.find_files(f\"{ROOT_DIR}/{folder}\", ext=['wav']) \n",
    "    files = np.asarray(files)\n",
    "    for file_path in files:\n",
    "        audio = librosa.load(file_path, sr=None, mono=True, offset=0.0, duration=None)\n",
    "        audio_file = librosa.effects.trim(audio[0])\n",
    "        spectrogram = signal.spectrogram(audio_file[0], nperseg=FFT_SIZE, fs=audio[1], noverlap=FFT_SIZE/2)\n",
    "        \n",
    "        spec = np.log(spectrogram[2]+.0001)    \n",
    "        L =  len(spec)\n",
    "        window_length = int(np.ceil(L/(no_of_window*0.5+0.5)))                              \n",
    "        # log normalize frequencies                                  \n",
    "    \n",
    "        \n",
    "        r = [int(min(FFT_SIZE-1,(i)*window_length*0.5)) for i in range(0,no_of_window+2) ] #windowing\n",
    "      \n",
    "        [[spec[r[i]:r[i+2]]] for i in range(0,no_of_window)] \n",
    "        max_freq = [np.max(spec[(r[i]):(r[i+2]),:]) for i in range(0,no_of_window)] #maximum frequency\n",
    "       \n",
    "        \n",
    "        mean_freq = [np.mean(spec[r[i]:r[i+2],:]) for i in range(0,no_of_window)]# MEAN FREQUENCY\n",
    "    \n",
    "        \n",
    "        std_freq = [np.std(spec[r[i]:r[i+2],:]) for i in range(0,no_of_window)]#std frequency \n",
    "    \n",
    "        \n",
    "      \n",
    "        feature_wind.loc[len(feature_wind)] = [folder]+ max_freq+ mean_freq+ std_freq   # append features to feature df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55544b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_data_wind = feature_wind[['max_freq', 'mean_freq', 'std_freq']]\n",
    "feature_labels = feature_df['label']\n",
    "scaler = RobustScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eddfd4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain, xtest, ytrain, ytest = train_test_split(feature_data_wind, feature_labels, test_size=0.30)\n",
    "\n",
    "#training the model\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(xtrain, ytrain)\n",
    "cv_scores = cross_val_score(clf, xtrain, ytrain, cv=10)\n",
    "print('Average Cross Validation Score from Training:', cv_scores.mean(), sep='\\n', end='\\n\\n\\n')\n",
    "\n",
    "#testing the model\n",
    "ypred = clf.predict(xtest)\n",
    "cm = confusion_matrix(ytest, ypred)\n",
    "cr = classification_report(ytest, ypred)\n",
    "\n",
    "print('Confusion Matrix:', cm, sep='\\n', end='\\n\\n\\n')\n",
    "print('Test Statistics:', cr, sep='\\n', end='\\n\\n\\n')\n",
    "\n",
    "#This is what we will be grading (>95 expected)\n",
    "print('Testing Accuracy:', accuracy_score(ytest, ypred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced5bb54",
   "metadata": {},
   "source": [
    "## MFCSS domain specific"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b614150f",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_path = \"/Users/damilolaojedeji/Documents/Classes/Fall 2022/ML/Assignment2/Siren/Siren1.wav\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8eec7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "wave_x, sampling_rate = librosa.load(full_path)\n",
    "ipd.Audio(wave_x, rate=sampling_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778886e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 4), facecolor=(.9, .9, .9))\n",
    "librosa.display.waveshow(wave_x, sr=sampling_rate, color='green')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0975ad39",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mfccs = librosa.feature.mfcc(wave_x, sr=sampling_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e671be11",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "librosa.display.specshow(mfccs, sr=sampling_rate, x_axis='time')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35302167",
   "metadata": {},
   "source": [
    "## Chroma - Domain specific feature "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca57c7f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "hop_length = 1024\n",
    "chromagram = librosa.feature.chroma_stft(wave_x, sr=sampling_rate, hop_length=hop_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0567ed13",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "librosa.display.specshow(chromagram, x_axis='time', y_axis='chroma', hop_length=hop_length, cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0318c028",
   "metadata": {},
   "outputs": [],
   "source": [
    "FFT_SIZE = 2048\n",
    "\n",
    "hop_length = 1024\n",
    "feature_ds = pd.DataFrame(columns = ['label']+['max_freq', 'mean_freq', 'std_freq'])\n",
    "for folder in Folders:\n",
    "    files = librosa.util.find_files(f\"{ROOT_DIR}/{folder}\", ext=['wav']) \n",
    "    files = np.asarray(files)\n",
    "    for file_path in files:\n",
    "        audio = librosa.load(file_path, sr=None, mono=True, offset=0.0, duration=None)\n",
    "        audio_file = librosa.effects.trim(audio[0]) #domain specific\n",
    "        \n",
    "        chromagram = librosa.feature.chroma_stft(audio_file[0], audio[1], hop_length=hop_length)\n",
    "        \n",
    "        #mfccs = librosa.feature.mfcc(audio_file[0], sr=audio[1])\n",
    "        #mfccs1 = sklearn.preprocessing.scale(mfccs, axis=1)\n",
    "       \n",
    "    \n",
    "        \n",
    "        \n",
    "        \n",
    "        max_freq = np.max(chromagram)\n",
    "      \n",
    "        mean_freq = np.mean(chromagram)\n",
    "  \n",
    "        \n",
    "        std_freq = np.std(chromagram)                   \n",
    "        \n",
    "        \n",
    "        feature_ds.loc[len(feature_ds_bin)] = [folder, max_freq, mean_freq, std_freq] \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f4acfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_data_ds = feature_ds_bin[['max_freq', 'mean_freq', 'std_freq']]\n",
    "feature_labels = feature_df['label']\n",
    "feature_ds_bin\n",
    "scaler = RobustScaler()\n",
    "feature_data_ds = scaler.fit_transform(feature_data_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ade08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain, xtest, ytrain, ytest = train_test_split(feature_data_ds, feature_labels, test_size=0.30)\n",
    "\n",
    "#training the model\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(xtrain, ytrain)\n",
    "cv_scores = cross_val_score(clf, xtrain, ytrain, cv=10)\n",
    "print('Average Cross Validation Score from Training:', cv_scores.mean(), sep='\\n', end='\\n\\n\\n')\n",
    "\n",
    "#testing the model\n",
    "ypred = clf.predict(xtest)\n",
    "cm = confusion_matrix(ytest, ypred)\n",
    "cr = classification_report(ytest, ypred)\n",
    "\n",
    "print('Confusion Matrix:', cm, sep='\\n', end='\\n\\n\\n')\n",
    "print('Test Statistics:', cr, sep='\\n', end='\\n\\n\\n')\n",
    "\n",
    "print('Testing Accuracy:', accuracy_score(ytest, ypred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a881ec50",
   "metadata": {},
   "source": [
    "## PREDICTION WITH WINDOWING (DOMAIN SPECIFIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1f0306",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_of_window = 5\n",
    "feature_wind_ds = pd.DataFrame(columns = ['label']+['max_freq', 'mean_freq', 'std_freq']*no_of_window)#+['spec_centroid'])\n",
    "\n",
    "\n",
    "\n",
    "# loop through .wav files\n",
    "for folder in Folders:\n",
    "    files = librosa.util.find_files(f\"{ROOT_DIR}/{folder}\", ext=['wav']) \n",
    "    files = np.asarray(files)\n",
    "    for file_path in files:\n",
    "        audio = librosa.load(file_path, sr=None, mono=True, offset=0.0, duration=None)\n",
    "        audio_file = librosa.effects.trim(audio[0])\n",
    "        chromagram = librosa.feature.chroma_stft(audio_file[0], audio[1], hop_length=hop_length)\n",
    "        \n",
    "        L =  len(chromagram)\n",
    "        window_length = int(np.ceil(L/(no_of_window*0.5+0.5)))                              \n",
    "                                     \n",
    "        \n",
    "       \n",
    "        # MAX FREQUENCY\n",
    "        r = [int(min(FFT_SIZE-1,(i)*window_length*0.5)) for i in range(0,no_of_window+2) ]\n",
    "      \n",
    "        [[spec[r[i]:r[i+2]]] for i in range(0,no_of_window)] \n",
    "        max_freq = [np.max(chromagram[(r[i]):(r[i+2]),:]) for i in range(0,no_of_window)]\n",
    "       \n",
    "        # MEAN FREQUENCY\n",
    "        #print(5)\n",
    "        mean_freq = [np.mean(chromagram[r[i]:r[i+2],:]) for i in range(0,no_of_window)]\n",
    "        #np.mean(spectrogram[2])\n",
    "        # STD DEV FREQUENCY\n",
    "        \n",
    "        std_freq = [np.std(chromagram[r[i]:r[i+2],:]) for i in range(0,no_of_window)]\n",
    "        #np.std(spectrogram[2])   \n",
    "        \n",
    "        # append features to feature df\n",
    "        feature_wind_ds.loc[len(feature_wind_ds)] = [folder]+ max_freq+ mean_freq+ std_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea9499d",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_data_wind_ds = feature_wind_ds[['max_freq', 'mean_freq', 'std_freq']]\n",
    "feature_labels = feature_df['label']\n",
    "scaler = RobustScaler()\n",
    "feature_data_wind_ds = scaler.fit_transform(feature_data_wind_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2288074",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain, xtest, ytrain, ytest = train_test_split(feature_data_wind_ds, feature_labels, test_size=0.30)\n",
    "\n",
    "#training the model\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(xtrain, ytrain)\n",
    "cv_scores = cross_val_score(clf, xtrain, ytrain, cv=10)\n",
    "print('Average Cross Validation Score from Training:', cv_scores.mean(), sep='\\n', end='\\n\\n\\n')\n",
    "\n",
    "#testing the model\n",
    "ypred = clf.predict(xtest)\n",
    "cm = confusion_matrix(ytest, ypred)\n",
    "cr = classification_report(ytest, ypred)\n",
    "\n",
    "print('Confusion Matrix:', cm, sep='\\n', end='\\n\\n\\n')\n",
    "print('Test Statistics:', cr, sep='\\n', end='\\n\\n\\n')\n",
    "\n",
    "#This is what we will be grading (>95 expected)\n",
    "print('Testing Accuracy:', accuracy_score(ytest, ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb23673",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
